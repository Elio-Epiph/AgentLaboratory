#!/usr/bin/env python3
"""
æµ‹è¯•æœ¬åœ° Qwen æ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
"""

import sys
import os
sys.path.append('.')

from inference import query_model

def test_local_qwen():
    """æµ‹è¯•æœ¬åœ° Qwen æ¨¡å‹"""
    print("Testing local Qwen model...")
    
    # æµ‹è¯•ç”¨çš„æ¨¡å‹è·¯å¾„
    model_path = "/data/kaohesheng/qiujinbo/Qwen2.5-1.5B-Instruct"
    model_str = f"qwen-local:{model_path}"
    
    # æµ‹è¯• prompt
    system_prompt = "You are a helpful AI assistant."
    prompt = "Hello, please introduce yourself briefly."
    
    try:
        print(f"Using model: {model_str}")
        print(f"System prompt: {system_prompt}")
        print(f"User prompt: {prompt}")
        print("-" * 50)
        
        # è°ƒç”¨æ¨¡å‹
        response = query_model(
            model_str=model_str,
            prompt=prompt,
            system_prompt=system_prompt,
            temp=0.7,
            print_cost=True
        )
        
        print("Response:")
        print(response)
        print("-" * 50)
        print("âœ… Local Qwen model test successful!")
        
    except Exception as e:
        print(f"âŒ Error testing local model: {e}")
        return False
    
    return True

def test_agentlab_config():
    """æµ‹è¯• AgentLaboratory é…ç½®"""
    print("\nTesting AgentLaboratory configuration...")
    
    try:
        import yaml
        with open('experiment_configs/MATH_agentlab.yaml', 'r') as f:
            config = yaml.safe_load(f)
        
        llm_backend = config.get('llm-backend', '')
        print(f"LLM Backend: {llm_backend}")
        
        if llm_backend.startswith('qwen-local:'):
            print("âœ… Configuration looks good for local Qwen!")
        else:
            print("âš ï¸  Configuration might need adjustment")
            
    except Exception as e:
        print(f"âŒ Error reading config: {e}")

if __name__ == "__main__":
    print("=" * 60)
    print("Local Qwen Model Test for AgentLaboratory")
    print("=" * 60)
    
    # æµ‹è¯•æœ¬åœ°æ¨¡å‹
    success = test_local_qwen()
    
    # æµ‹è¯•é…ç½®
    test_agentlab_config()
    
    if success:
        print("\nğŸ‰ All tests passed! You can now run AgentLaboratory with local Qwen.")
        print("\nTo run AgentLaboratory:")
        print("python ai_lab_repo.py --config experiment_configs/MATH_agentlab.yaml")
    else:
        print("\nâŒ Tests failed. Please check the error messages above.") 