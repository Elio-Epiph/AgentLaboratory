# If you want to have user input or be a human-in-the-loop
copilot-mode: False

# Here is the research prompt. If num-papers-to-write > 1, you can treat this as a "research direction" otherwise it can be *very* specific and can be treated as a full research idea
research-topic: "Prompt Engineering on GSM8K to Evaluate Qwen's Arithmetic Problem-Solving Ability"

# Local model configuration (no API key needed)
# api-key: "sk-zk2ea9cda550517658186d2f7edd09236c66873c80a55b90"
# or deepseek-api-key: "DEEPSEEK-API-KEY-HERE"
# Agent Laboratory backend - using local Qwen model
llm-backend: "qwen-local:/data/kaohesheng/qiujinbo/Qwen2.5-1.5B-Instruct"
# Literature review backend - using local Qwen model
lit-review-backend: "qwen-local:/data/kaohesheng/qiujinbo/Qwen2.5-1.5B-Instruct"

# Base language
language: "English"

# Number of arxiv papers to lit review
num-papers-lit-review: 5
# Total number of papers to write in sequence
num-papers-to-write: 1
# Do you want to run multiple agent labs in parallel?
parallel-labs: False

# Total mle-solver steps per lab
mlesolver-max-steps: 3
# Total paper-solver steps per lab
papersolver-max-steps: 1
# The lab index for this lab (used for parallel runs)
lab-index: 1
# If you want to load an existing save
load-previous: False
# If fail, run exception?
except-if-fail: False
# Compile latex into PDFs during paper-solver
compile-latex: False

# Task notes
task-notes:
  plan-formulation:
    - 'Design a simple prompting technique to solve arithmetic word problems from the GSM8K dataset.'
    - 'Use Qwen as the language model.'
    - 'Your goal is not to beat the SOTA but to demonstrate successful execution of the pipeline.'
    - 'Use only 10 randomly selected questions from GSM8K (seed=42).'
    - 'DO NOT spend too long on prompt design - a clear instruction prompt is sufficient.'
  data-preparation:
    - 'Use the GSM8K dataset from HuggingFace. Sample 10 test examples with seed=42.'
    - 'You may use the following code:\nfrom datasets import load_dataset\nimport random\nrandom.seed(42)\ngsm8k = load_dataset("gsm8k", "main")["test"]\nsample = random.sample(list(gsm8k), 10)'
  running-experiments:
    - 'Use query_qwen_local(prompt=..., system_prompt=..., model_path=...) to get the Qwen model response'
    - 'Wrap the arithmetic problem in a clear instruction prompt.'
    - 'Use multiprocessing to parallelize 10-question inference.'
    - 'Check if model answer matches ground truth using simple string comparison or normalization.'
  results-interpretation:
    - 'Report how many questions were correct out of 10.'
    - 'Optionally print each problem + model answer + correct answer.'
  report-writing:
    - 'Summarize the experiment and include the final accuracy.'
    - 'Explain briefly the prompting strategy.'
    - 'You may include a simple bar chart or table to present results.'
